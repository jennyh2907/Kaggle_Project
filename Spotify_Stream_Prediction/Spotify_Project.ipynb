{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "import statsmodels.api as sm\n",
    "import random\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "import xgboost as xgb\n",
    "import pickle"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Supervised: Predicting Streams "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Data Exploration & Step 2: Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the data\n",
    "music = pd.read_csv(\"spotify_dataset.csv\")\n",
    "\n",
    "# Convert to dataframe\n",
    "df = pd.DataFrame(music)\n",
    "\n",
    "# Data Exploration: Check the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Check null data\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Check data type\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Which genre is the most common ones? \n",
    "# Create a list to contain all genre\n",
    "total_genre = []\n",
    "\n",
    "# Data Exploration: Split each genre lists as independent element  \n",
    "df[\"Genre\"] = df[\"Genre\"].str.split(\",\")\n",
    "\n",
    "# Data Exploration: Loop through each genre\n",
    "for i, genre_list in enumerate(df[\"Genre\"]):\n",
    "    for single_genre in genre_list:\n",
    "        cleaned_genre = single_genre.strip(\"['] \")\n",
    "        # Store cleaned genre in the list\n",
    "        total_genre.append(cleaned_genre)\n",
    "\n",
    "# Data Exploration: Observe the most common genre\n",
    "count_genre = Counter(total_genre)\n",
    "print(count_genre.most_common())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning: Convert streams to integer\n",
    "df['Streams'] = (df['Streams'].replace(',','', regex = True)).astype(int)\n",
    "print(df['Streams'])\n",
    "\n",
    "# Data Cleaning: Convert release date into datetime\n",
    "df[\"Release Date\"] = df[\"Release Date\"].str.strip()\n",
    "df[\"Release Date\"] = pd.to_datetime(df[\"Release Date\"], format = \"%Y-%m-%d\")\n",
    "df[\"Release Date\"] = df[\"Release Date\"].apply(lambda x: x.year)\n",
    "\n",
    "# Data Cleaning: Convert other columns into numeric data\n",
    "numeric_list = [\"Artist Followers\", \"Popularity\", \"Danceability\", \"Energy\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Tempo\", \"Duration (ms)\", \"Valence\"]\n",
    "for i in numeric_list: \n",
    "    df[i] = pd.to_numeric(df[i], errors = \"coerce\")\n",
    "\n",
    "# Data Cleaning: Create dummies for chord column\n",
    "chord_dummy = pd.get_dummies(df[\"Chord\"], prefix = \"Chord\")\n",
    "df = df.join(chord_dummy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning: Initiate the dummy column as 0\n",
    "df[[\"Rock\", \"Pop\", \"Hip Hop\", \"Rap\", \"Trap\"]] = 0\n",
    "\n",
    "# Data Cleaning: Loop through each genre\n",
    "for i, genre_list in enumerate(df[\"Genre\"]):\n",
    "    for single_genre in genre_list:\n",
    "        cleaned_genre = single_genre.strip(\"[']\")\n",
    "        # Update the value of dummy columns when matched\n",
    "        if \"rock\" in cleaned_genre:\n",
    "            df.loc[i, \"Rock\"] = 1 \n",
    "        if \"pop\" in cleaned_genre:\n",
    "            df.loc[i, \"Pop\"] = 1  \n",
    "        if \"hip hop\" in cleaned_genre:\n",
    "            df.loc[i, \"Hip Hop\"] = 1  \n",
    "        if \"trap\" in cleaned_genre:\n",
    "            df.loc[i, \"Trap\"] = 1 \n",
    "        elif \"rap\" in cleaned_genre:\n",
    "            df.loc[i, \"Rap\"] = 1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Cleaning: Drop columns that are not important or being replaced by dummies\n",
    "cleaned_df = df.drop([\"Week of Highest Charting\", \"Song ID\", \"Genre\", \"Weeks Charted\", \"Index\", \"Chord\", \"Song Name\", \"Artist\"], axis = 1)\n",
    "\n",
    "# Print the cleaned dataframe\n",
    "cleaned_df "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Streams\"])\n",
    "plt.xlabel(\"Streams\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Streams frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Artist Followers\"])\n",
    "plt.xlabel(\"Number of Followers\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Number of Followers frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Release Date\"])\n",
    "plt.xlabel(\"Release Date\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Release Date frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Popularity\"])\n",
    "plt.xlabel(\"Popularity\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Year of Release frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Danceability\"])\n",
    "plt.xlabel(\"Danceability\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Danceability frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Energy\"])\n",
    "plt.xlabel(\"Energy\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Energy frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Loudness\"])\n",
    "plt.xlabel(\"Loudness\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Loudness frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Speechiness\"])\n",
    "plt.xlabel(\"Speechiness\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Speechiness frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Acousticness\"])\n",
    "plt.xlabel(\"Acousticness\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Acousticness frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Liveness\"])\n",
    "plt.xlabel(\"Liveness\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Liveness frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Tempo\"])\n",
    "plt.xlabel(\"Tempo\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Tempo frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Duration (ms)\"])\n",
    "plt.xlabel(\"Duration (ms)\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Duration (ms) frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Valence\"])\n",
    "plt.xlabel(\"Valence\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Valence frequencies\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Exploration: Data Visualization\n",
    "plt.hist(df[\"Chord\"])\n",
    "plt.xlabel(\"Chord\")\n",
    "plt.ylabel(\"Frequency\")\n",
    "plt.title(\"Chord frequencies\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data Preprocessing: Scale the data except dummies, song name and artist\n",
    "final_df = cleaned_df.copy()\n",
    "scaled_feature = [\"Number of Times Charted\", \"Streams\", \"Artist Followers\", \"Release Date\", \"Popularity\", \"Danceability\", \"Energy\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Tempo\", \"Duration (ms)\", \"Valence\"]\n",
    "\n",
    "# Use Standard Scaler to specific column\n",
    "features = final_df[scaled_feature]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "final_df[scaled_feature] = features\n",
    "\n",
    "# Drop NAs\n",
    "final_df = final_df.dropna()\n",
    "final_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training group and testing group\n",
    "random.seed(123)\n",
    "x = final_df[[\"Highest Charting Position\", \"Number of Times Charted\", \"Artist Followers\", \"Release Date\", \"Popularity\", \"Danceability\", \"Energy\", \"Loudness\", \"Speechiness\", \"Acousticness\", \"Liveness\", \"Tempo\", \"Duration (ms)\", \"Valence\", \"Chord_ \", \"Chord_A\", \"Chord_A#/Bb\", \"Chord_B\", \"Chord_C\", \"Chord_C#/Db\", \"Chord_D\", \"Chord_D#/Eb\", \"Chord_E\", \"Chord_F\", \"Chord_F#/Gb\", \"Chord_G\", \"Chord_G#/Ab\", \"Rock\", \"Pop\", \"Hip Hop\", \"Rap\", \"Trap\"]]\n",
    "y = final_df[\"Streams\"]\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Selection: Use CV to find the optimal alpha for LASSO\n",
    "alphas = np.logspace(-4, 0, 100)\n",
    "\n",
    "# Fit a Lasso regression model for each alpha value\n",
    "model = LassoCV(alphas = alphas, cv = 5)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Evaluate each model on the validation set using MSE and select the best MSE\n",
    "mse_values = np.mean((model.predict(x_test) - y_test) ** 2, axis = 0)\n",
    "best_alpha = model.alpha_\n",
    "best_alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LASSO Regression\n",
    "model = Lasso(alpha = best_alpha)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Validate with test set and get MSE\n",
    "y_pred = model.predict(x_test)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "\n",
    "# Choose those coefficents != 0\n",
    "lasso_x_train = x_train.iloc[:,model.coef_!=0]\n",
    "print(lasso_x_train)\n",
    "lasso_col = lasso_x_train.columns.tolist()\n",
    "#print(lasso_col)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Supervised Model Building: Prediction\n",
    "\n",
    "    1. Linear Regression \n",
    "    2. Tree \n",
    "    3. Random Forest \n",
    "    4. XGBoost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract Lasso selcted column from x_test\n",
    "lasso_x_test = x_test[lasso_col]\n",
    "\n",
    "# Linear Regression\n",
    "linear_model = LinearRegression().fit(lasso_x_train , y_train)\n",
    "\n",
    "# Cross Validation\n",
    "cv_scores = cross_val_score(linear_model, lasso_x_train, y_train, cv=10)\n",
    "\n",
    "# Get mean CV score\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "print(cv_scores , \"\\n\\n\"\"mean =\" ,\"{:.2f}\".format(cv_scores_mean))\n",
    "\n",
    "# Save model\n",
    "linear_filename = 'finalized_linear_model.sav'\n",
    "pickle.dump(linear_model, open(linear_filename, 'wb'))\n",
    "\n",
    "# Load the pickled model\n",
    "linear_from_pickle = pickle.load(open(linear_filename, 'rb'))\n",
    "\n",
    "# Use the loaded pickled model to make predictions\n",
    "y_pred_linear = linear_from_pickle.predict(lasso_x_test)\n",
    "\n",
    "\n",
    "# Use MSE to evaluate\n",
    "linear_mse = mean_squared_error(y_pred_linear, y_test)\n",
    "print(\"Linear Regression MSE:\", linear_mse)\n",
    "\n",
    "# Evaluate accuracy score\n",
    "linear_score = linear_from_pickle.score(lasso_x_test , y_test)\n",
    "print(\"Linear Regression Accuracy Score:\", linear_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tree model\n",
    "tree_model = DecisionTreeRegressor(random_state=44)\n",
    "tree_model.fit(lasso_x_train, y_train)\n",
    "\n",
    "# Cross Validation\n",
    "cv_scores = cross_val_score(tree_model, lasso_x_train, y_train, cv=10)\n",
    "\n",
    "# Get mean CV score\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "print(cv_scores , \"\\n\\n\"\"mean =\" ,\"{:.2f}\".format(cv_scores_mean))\n",
    "\n",
    "# Save model\n",
    "tree_filename = 'finalized_tree_model.sav'\n",
    "pickle.dump(tree_model, open(tree_filename, 'wb'))\n",
    "\n",
    "# Load the pickled model\n",
    "tree_from_pickle = pickle.load(open(tree_filename, 'rb'))\n",
    "\n",
    "# Use the loaded pickled model to make predictions\n",
    "y_pred_tree = tree_from_pickle.predict(lasso_x_test)\n",
    "\n",
    "# Use MSE to evaluate\n",
    "tree_mse = mean_squared_error(y_pred_tree, y_test)\n",
    "print(\"Tree MSE:\", tree_mse)\n",
    "\n",
    "# Evaluate accuracy score\n",
    "tree_score = tree_from_pickle.score(lasso_x_test , y_test)\n",
    "print(\"Tree Accuracy Score:\", tree_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random Forest\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 40)\n",
    "\n",
    "# Train the model on training data\n",
    "rf.fit(lasso_x_train, y_train)\n",
    "\n",
    "# Cross Validation\n",
    "cv_scores = cross_val_score(rf, lasso_x_train, y_train, cv = 10)\n",
    "\n",
    "# Get mean CV score\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "print(cv_scores , \"\\n\\n\"\"mean =\" ,\"{:.2f}\".format(cv_scores_mean))\n",
    "\n",
    "# Save model\n",
    "rf_filename = 'finalized_rf_model.sav'\n",
    "pickle.dump(rf, open(rf_filename, 'wb'))\n",
    "\n",
    "# Load the pickled model\n",
    "rf_from_pickle = pickle.load(open(rf_filename, 'rb'))\n",
    "  \n",
    "# Use the loaded pickled model to make predictions\n",
    "y_pred_rf = rf_from_pickle.predict(lasso_x_test)\n",
    "\n",
    "# Use MSE to evaluate\n",
    "rf_mse = mean_squared_error(y_pred_rf, y_test)\n",
    "print(\"Random Forest MSE\", rf_mse)\n",
    "\n",
    "# Evaluate accuracy score\n",
    "rf_accu = rf_from_pickle.score(lasso_x_test, y_test)\n",
    "print(\"Random Forest Accuracy Score:\", rf_accu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XGBoost\n",
    "xgbr = xgb.XGBRegressor(booster = \"gbtree\", \n",
    "                        subsample = 0.8, \n",
    "                        eval_metric = 'rmse', \n",
    "                        max_depth = 5, \n",
    "                        objective = 'reg:squarederror',\n",
    "                        verbosity = 0) \n",
    "xgbr.fit(lasso_x_train, y_train, eval_set = [(lasso_x_train, y_train), (lasso_x_test, y_test)], verbose = 100)\n",
    "\n",
    "# Cross Validation\n",
    "cv_scores = cross_val_score(xgbr, lasso_x_train, y_train, cv = 10)\n",
    "\n",
    "# Get mean CV score\n",
    "cv_scores_mean = np.mean(cv_scores)\n",
    "print(cv_scores , \"\\n\\n\"\"mean =\" ,\"{:.2f}\".format(cv_scores_mean))\n",
    "\n",
    "# Save model\n",
    "xgb_filename = 'finalized_xgb_model.sav'\n",
    "pickle.dump(xgbr, open(xgb_filename, 'wb'))\n",
    "\n",
    "# Load the pickled model\n",
    "xgb_from_pickle = pickle.load(open(xgb_filename, 'rb'))\n",
    "\n",
    "# Use the loaded pickled model to make predictions\n",
    "y_pred_xgb = xgb_from_pickle.predict(lasso_x_test)\n",
    "\n",
    "# Use MSE to evaluate\n",
    "xgb_mse = mean_squared_error(y_pred_xgb, y_test)\n",
    "print(\"XGB MSE:\", xgb_mse)\n",
    "\n",
    "# Evaluate accuracy score\n",
    "xgb_accu = xgb_from_pickle.score(lasso_x_test, y_test)\n",
    "print(\"XGB Accuracy Score:\", xgb_accu)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
